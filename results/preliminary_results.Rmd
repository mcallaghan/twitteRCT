---
title: "Preliminary Results"
author: "Group 3"
date: "April 25, 2016"
output:
  pdf_document:
    fig_caption: yes
---



```{r connect,echo=FALSE,warning=FALSE,message=FALSE}

setwd("..")

library(RMySQL)
library(ggplot2)
library(dplyr)
library(tidyr)
library(plm)
library(knitr)
library(R.utils)
library(stargazer)
library(xtable)
library(ggmap)

opts_chunk$set(fig.height=8,fig.width=8,warning=FALSE,echo=FALSE,message=FALSE)

sourceDirectory("functions/",modifiedOnly = FALSE)

# con <- try(dbConnect(MySQL(),
#                      group='trump'),
#            silent=TRUE
#            )
# 
# if(class(con) != "try-error") {
#   get_data(con)
# 
# } 

load("data/likes.Rda")
load("data/tweets.Rda")
load("data/sent_tweets.Rda")
load("data/sample.Rda")
load("data/sample_info.Rda")
load("data/last_download.Rda")

load("data/usa_map.Rdata")
 


```



```{r process, echo=FALSE,message=FALSE,warning=FALSE}

sample <- sample %>%
  left_join(sample_info)

#############################################
## Get counts of n likes for each user on each day
like_users <- likes %>%
  group_by(user_id,like_date) %>%
  summarise(
    like_n = length(PID)
    )

#############################################
## Get counts of n tweet data for each user on each day
tweet_users <- tweets %>%
  group_by(user_id,tweet_date) %>%
  summarise(
    tweet_n = length(PID),
    trump_rt_n = sum(trump_retweet),
    trump_mention_n = sum(trump_mention),
    MAGA_n = sum(MAGA),
    trump_keyword_n = sum(trump_keyword)
  )

#############################################
## Get counts of sent tweets at each user on each day, and show truth value
sent_tweets$day <- as.character(as.Date(sent_tweets$time_sent))
sent_tweets_users <- sent_tweets %>%
  group_by(user,day,truth) %>%
  summarise(
    sent_n = length(PID)
  )


####################################################################
## Create a dataframe with a row for each user*day combination

days <- sort(unique(like_users$like_date))
users <- unique(like_users$user_id)

user_id <- rep(users,each=length(days))
date <- rep(days,times=length(users))

user_days <- data.frame(user_id,date)

####################################################################
## Merge this panel dataset with the others so that we get counts of 
## each variable for each user on each day, replace NAs (where there)
## were no tweets or likes recorded with 0s

user_days <- user_days %>%
  left_join(like_users,by=c("date" = "like_date","user_id" = "user_id")) %>%
  left_join(tweet_users,by=c("date" = "tweet_date","user_id" = "user_id")) %>%
  left_join(sample) %>%
  left_join(sent_tweets_users,by=c("date" = "day","username" = "user")) %>%
  select(user_id,date,username,t_group,like_n:trump_keyword_n,sent_n,truth,location:friends_count)


user_days[is.na(user_days)] <- 0

user_days$date_d <- as.Date(user_days$date)




#########################################
## Summarise Group Averages
group_avs <-  user_days %>% 
  group_by(t_group,date) %>%
  summarise(
    average_likes = mean(like_n),
    average_rts = mean(trump_rt_n),
    average_mentions = mean(trump_mention_n),
    average_MAGA = mean(MAGA_n),
    average_keywords = mean(trump_keyword_n),
    average_tweets = mean(tweet_n),
    average_sent = mean(sent_n),
    average_truth = sum(truth) / sum(sent_n)
  ) 


########################
## Summarise User avs across days
user_avs <-  user_days %>% 
  filter(date_d < as.Date("2016-04-14")) %>%
  group_by(user_id) %>%
  summarise(
    average_likes = mean(like_n),
    average_rts = mean(trump_rt_n),
    average_mentions = mean(trump_mention_n),
    average_MAGA = mean(MAGA_n),
    average_keywords = mean(trump_keyword_n),
    average_tweets = mean(tweet_n),
    average_sent = mean(sent_n)
  ) 

#format(now,"%B %d %Y")

```

The data in this document were pulled from a database on `r format(now,"%B %d %Y")` at `r format(now,"%H:%M")`. As like and tweet data is collected on a rolling basis, not all likes and tweets made up to that time are included.

## Descriptive Statistics

We show summary statistics for the treatment and control groups in the period before the treatment started, and plot frequency density plots of followers and friends counts.

```{r descristive, echo=FALSE,message=FALSE,warning=FALSE}

user_avs_long <- user_avs %>%
  left_join(sample) %>%
  select(user_id,username,t_group,location,average_likes:average_keywords,followers_count,friends_count) %>%
  gather(variable,value,average_likes:friends_count) 

user_avs_summary <- user_avs_long %>%
  group_by(variable) %>%
  summarise(
    mean = mean(value,na.rm=TRUE),
    median = median(value,na.rm=TRUE),
    SE = sd(value,na.rm=TRUE)/sqrt(length(value))
  ) %>%
  ungroup()

user_avs_summary_split <- user_avs_long %>%
  group_by(variable,t_group) %>%
  summarise(
    mean = mean(value,na.rm=TRUE),
    median = median(value,na.rm=TRUE),
    SE = sd(value,na.rm=TRUE)/sqrt(length(value))
  ) %>%
  ungroup()

treatment <- user_avs_summary_split %>%
  filter(t_group == "T") %>%
  select(-t_group)

control <- user_avs_summary_split  %>%
  filter(t_group == "C") %>%
  select(-t_group)

kable(treatment,caption="Summary statistics - treatment group")

kable(control,caption="Summary statistics - control group")


#############################################
## Plot followers count

followers <- ggplot(
  sample,
  aes(followers_count,..density..,colour=t_group)
  ) + 
  geom_freqpoly() +
  theme_bw()

#############################################
## Plot friends count

friends <- ggplot(
  sample,
  aes(friends_count,..density..,colour=t_group)
) + 
  geom_freqpoly() +
  theme_bw()

############################################
## Be careful with the Rmisc package, it hides
## the summarise function from dplyr - don't
## load it in library
Rmisc::multiplot(followers,friends)



```

The map in figure [#] shows the distribution of the self-reported location of our observation group around the US (note that not all users report their location, not all users truthfully report their location, and not all locations are necessarily geocoded correctly)

```{r map, echo=FALSE, message=FALSE,fig.cap="Location of observation group"}



geo_sample <- sample %>%
  filter(lat > 0)

ggmap(map) +
  geom_jitter(
    aes(x=lng,y=lat,colour=t_group),
    size=0.5,
    data=geo_sample
  ) + theme_void()

```


## Treatment

Table [#] gives examples of the tweets we sent to our treatment group

```{r example_tweets, echo=FALSE, message=FALSE,results="asis"}

tweet_examples <- sent_tweets %>%
  group_by(tweet_no) %>%
  arrange(PID) %>%
  filter(row_number()==1) %>%
  select(text,truth,day) %>%
  rename(`start date` = day) %>%
  mutate(
    tlength = nchar(text),
    nspaces = length(strsplit(text," ")[[1]]),
    nmid = nspaces/2,
    nmid1 = nmid + 1,
    w1 = paste(strsplit(text," ")[[1]][1:nmid],collapse=" "),
    w2 = paste(strsplit(text," ")[[1]][nmid1:nspaces],collapse=" "),
    broken_text = paste(w1,w2,sep="\n"),
    start_date_adj = ifelse(
      `start date` == "2016-04-30",
      "2016-05-01",
      `start date`
    )
  )

print(xtable(
  select(tweet_examples,text,truth,`start date`),
  align=c(
    "c",
    "c",
    "p{8cm}",
    "c",
    "c"),
  caption="Example tweets",
  label="table:example_tweets",
  table.placement="!h"
  ),
  include.rownames=FALSE,
  comment=FALSE
      )

```


## Results

We measure likes of trump tweets on each day, compare treatment and control groups, and show the fraction of the treatment group receiving treatment on each day with colour coded bars. The truth values of the bars are colour coded according to the schema in table [#]


| Truth         | Truth value   |
| ------------- |:-------------:|
| True          | 2             |
| Mostly true   | 1             |
| Half true     | 0             |
| Mostly false  | -1            |
| False         | -2            |

\newpage

```{r likes, echo=FALSE,message=FALSE,warning=FALSE,fig.cap="Average likes of Trump tweets"}

#####################################
## Plot likes
plot_tc('average_likes',t=0.6) 

```


We also collect all tweets sent by each member of our observation group (removing those which are a retweet or a reply to one of our accounts). We categorise those tweets to measure various indicators of engagement with Trump. These are shown in figures [#] to [#]

```{r rts, echo=FALSE,message=FALSE,warning=FALSE, fig.cap="Average retweets of Trump"}


plot_tc('average_rts',t=0.6)

```


```{r mentions, echo=FALSE,message=FALSE,warning=FALSE, fig.cap="Averages tweets containing @RealDonaldTrump"}

plot_tc('average_mentions',t=0.6)

```



```{r MAGA, echo=FALSE,message=FALSE,warning=FALSE, fig.cap="Average tweets using the hashtag #MakeAmericaGreatAgain"}

plot_tc('average_MAGA',t=0.6)

```


```{r keywords, echo=FALSE,message=FALSE,warning=FALSE, fig.cap="Average tweets containing the word Trump"}

plot_tc('average_keywords',t=0.6)

```


```{r tweets, echo=FALSE,message=FALSE,warning=FALSE, fig.cap="Average tweets"}

plot_tc('average_tweets',t=0.6)

```


### Numerical results

We have run simple regressions interacting the time variable and the treatment variable, to see if the differences between T and C groups on each day were significant.

```{r models, echo=FALSE,message=FALSE,warning=FALSE,results="asis"}

model_likes <- lm(like_n ~ t_group*date,data=user_days)

model_rts <- lm(trump_rt_n ~ t_group*date,data=user_days)

model_maga <- lm(MAGA_n ~ t_group*date,data=user_days)

model_keyword <- lm(trump_keyword_n ~ t_group*date,data=user_days)

stargazer(model_likes,model_rts,model_maga,model_keyword,omit="^date",single.row=TRUE,header=FALSE)


```

